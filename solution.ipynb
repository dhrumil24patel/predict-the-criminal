{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier, cv, CatboostIpythonWidget\n",
    "\n",
    "from auto_ml import Predictor\n",
    "from auto_ml.utils_models import load_ml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/criminal_test.csv\")\n",
    "train= pd.read_csv(\"./data/criminal_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuers = train.columns[train.columns != \"Criminal\"]\n",
    "X = train[featuers]\n",
    "Y = train['Criminal']\n",
    "list = ['PERID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = train.drop(list,axis=1)\n",
    "y = test.drop(list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = ['TROUBUND']\n",
    "x = x.drop(list1,axis=1)\n",
    "y = y.drop(list1,axis=1)\n",
    "x = x.drop('Criminal',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(x, Y, train_size=0.85, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to auto_ml! We're about to go through and make sense of your data using machine learning, and give you a production-ready pipeline to get predictions with.\n",
      "\n",
      "If you have any issues, or new feature ideas, let us know at http://auto.ml\n",
      "Now using the model training_params that you passed in:\n",
      "{'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 14, 'lambda_l2': 0.002, 'histogram_pool_size': 16384}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 14, 'lambda_l2': 0.002, 'histogram_pool_size': 16384}\n",
      "Running basic data cleaning\n",
      "Fitting DataFrameVectorizer\n",
      "Now using the model training_params that you passed in:\n",
      "{'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 14, 'lambda_l2': 0.002, 'histogram_pool_size': 16384}\n",
      "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
      "{'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 14, 'lambda_l2': 0.002, 'histogram_pool_size': 16384}\n",
      "\n",
      "\n",
      "********************************************************************************************\n",
      "About to fit the pipeline for the model LGBMClassifier to predict Criminal\n",
      "Started at:\n",
      "2018-02-08 17:02:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\lightgbm\\basic.py:1029: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is []\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\trandom_holdout_set_from_training_data's binary_logloss: 0.536578\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\trandom_holdout_set_from_training_data's binary_logloss: 0.431746\n",
      "[3]\trandom_holdout_set_from_training_data's binary_logloss: 0.356623\n",
      "[4]\trandom_holdout_set_from_training_data's binary_logloss: 0.300984\n",
      "[5]\trandom_holdout_set_from_training_data's binary_logloss: 0.258593\n",
      "[6]\trandom_holdout_set_from_training_data's binary_logloss: 0.226031\n",
      "[7]\trandom_holdout_set_from_training_data's binary_logloss: 0.200565\n",
      "[8]\trandom_holdout_set_from_training_data's binary_logloss: 0.180488\n",
      "[9]\trandom_holdout_set_from_training_data's binary_logloss: 0.164753\n",
      "[10]\trandom_holdout_set_from_training_data's binary_logloss: 0.152097\n",
      "[11]\trandom_holdout_set_from_training_data's binary_logloss: 0.141988\n",
      "[12]\trandom_holdout_set_from_training_data's binary_logloss: 0.133673\n",
      "[13]\trandom_holdout_set_from_training_data's binary_logloss: 0.127031\n",
      "[14]\trandom_holdout_set_from_training_data's binary_logloss: 0.121758\n",
      "[15]\trandom_holdout_set_from_training_data's binary_logloss: 0.117505\n",
      "[16]\trandom_holdout_set_from_training_data's binary_logloss: 0.113961\n",
      "[17]\trandom_holdout_set_from_training_data's binary_logloss: 0.110962\n",
      "[18]\trandom_holdout_set_from_training_data's binary_logloss: 0.108746\n",
      "[19]\trandom_holdout_set_from_training_data's binary_logloss: 0.106853\n",
      "[20]\trandom_holdout_set_from_training_data's binary_logloss: 0.105455\n",
      "[21]\trandom_holdout_set_from_training_data's binary_logloss: 0.104245\n",
      "[22]\trandom_holdout_set_from_training_data's binary_logloss: 0.10329\n",
      "[23]\trandom_holdout_set_from_training_data's binary_logloss: 0.102567\n",
      "[24]\trandom_holdout_set_from_training_data's binary_logloss: 0.101829\n",
      "[25]\trandom_holdout_set_from_training_data's binary_logloss: 0.101408\n",
      "[26]\trandom_holdout_set_from_training_data's binary_logloss: 0.100895\n",
      "[27]\trandom_holdout_set_from_training_data's binary_logloss: 0.100556\n",
      "[28]\trandom_holdout_set_from_training_data's binary_logloss: 0.100385\n",
      "[29]\trandom_holdout_set_from_training_data's binary_logloss: 0.100052\n",
      "[30]\trandom_holdout_set_from_training_data's binary_logloss: 0.0998922\n",
      "[31]\trandom_holdout_set_from_training_data's binary_logloss: 0.0996708\n",
      "[32]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994761\n",
      "[33]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993127\n",
      "[34]\trandom_holdout_set_from_training_data's binary_logloss: 0.099274\n",
      "[35]\trandom_holdout_set_from_training_data's binary_logloss: 0.0992568\n",
      "[36]\trandom_holdout_set_from_training_data's binary_logloss: 0.0992043\n",
      "[37]\trandom_holdout_set_from_training_data's binary_logloss: 0.0991671\n",
      "[38]\trandom_holdout_set_from_training_data's binary_logloss: 0.0991591\n",
      "[39]\trandom_holdout_set_from_training_data's binary_logloss: 0.0988985\n",
      "[40]\trandom_holdout_set_from_training_data's binary_logloss: 0.0988727\n",
      "[41]\trandom_holdout_set_from_training_data's binary_logloss: 0.0987827\n",
      "[42]\trandom_holdout_set_from_training_data's binary_logloss: 0.0987531\n",
      "[43]\trandom_holdout_set_from_training_data's binary_logloss: 0.0987554\n",
      "[44]\trandom_holdout_set_from_training_data's binary_logloss: 0.0987407\n",
      "[45]\trandom_holdout_set_from_training_data's binary_logloss: 0.0987595\n",
      "[46]\trandom_holdout_set_from_training_data's binary_logloss: 0.0986023\n",
      "[47]\trandom_holdout_set_from_training_data's binary_logloss: 0.0986421\n",
      "[48]\trandom_holdout_set_from_training_data's binary_logloss: 0.0988066\n",
      "[49]\trandom_holdout_set_from_training_data's binary_logloss: 0.09883\n",
      "[50]\trandom_holdout_set_from_training_data's binary_logloss: 0.0988997\n",
      "[51]\trandom_holdout_set_from_training_data's binary_logloss: 0.098935\n",
      "[52]\trandom_holdout_set_from_training_data's binary_logloss: 0.0989125\n",
      "[53]\trandom_holdout_set_from_training_data's binary_logloss: 0.0990526\n",
      "[54]\trandom_holdout_set_from_training_data's binary_logloss: 0.0991601\n",
      "[55]\trandom_holdout_set_from_training_data's binary_logloss: 0.0992982\n",
      "[56]\trandom_holdout_set_from_training_data's binary_logloss: 0.0992788\n",
      "[57]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993519\n",
      "[58]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994442\n",
      "[59]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993522\n",
      "[60]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993838\n",
      "[61]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993898\n",
      "[62]\trandom_holdout_set_from_training_data's binary_logloss: 0.099429\n",
      "[63]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994738\n",
      "[64]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994942\n",
      "[65]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995949\n",
      "[66]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995771\n",
      "[67]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994915\n",
      "[68]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994937\n",
      "[69]\trandom_holdout_set_from_training_data's binary_logloss: 0.099462\n",
      "[70]\trandom_holdout_set_from_training_data's binary_logloss: 0.0996607\n",
      "[71]\trandom_holdout_set_from_training_data's binary_logloss: 0.0997551\n",
      "[72]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995505\n",
      "[73]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995731\n",
      "[74]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995465\n",
      "[75]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995521\n",
      "[76]\trandom_holdout_set_from_training_data's binary_logloss: 0.0996083\n",
      "[77]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995281\n",
      "[78]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994187\n",
      "[79]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994059\n",
      "[80]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994413\n",
      "[81]\trandom_holdout_set_from_training_data's binary_logloss: 0.099386\n",
      "[82]\trandom_holdout_set_from_training_data's binary_logloss: 0.099276\n",
      "[83]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993261\n",
      "[84]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994001\n",
      "[85]\trandom_holdout_set_from_training_data's binary_logloss: 0.0993808\n",
      "[86]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994217\n",
      "[87]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994506\n",
      "[88]\trandom_holdout_set_from_training_data's binary_logloss: 0.0994066\n",
      "[89]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995277\n",
      "[90]\trandom_holdout_set_from_training_data's binary_logloss: 0.0995362\n",
      "[91]\trandom_holdout_set_from_training_data's binary_logloss: 0.0997039\n",
      "[92]\trandom_holdout_set_from_training_data's binary_logloss: 0.0998042\n",
      "[93]\trandom_holdout_set_from_training_data's binary_logloss: 0.0999111\n",
      "[94]\trandom_holdout_set_from_training_data's binary_logloss: 0.0997762\n",
      "[95]\trandom_holdout_set_from_training_data's binary_logloss: 0.0998044\n",
      "[96]\trandom_holdout_set_from_training_data's binary_logloss: 0.0998936\n",
      "[97]\trandom_holdout_set_from_training_data's binary_logloss: 0.100022\n",
      "[98]\trandom_holdout_set_from_training_data's binary_logloss: 0.100145\n",
      "[99]\trandom_holdout_set_from_training_data's binary_logloss: 0.100078\n",
      "[100]\trandom_holdout_set_from_training_data's binary_logloss: 0.100109\n",
      "[101]\trandom_holdout_set_from_training_data's binary_logloss: 0.100065\n",
      "[102]\trandom_holdout_set_from_training_data's binary_logloss: 0.100119\n",
      "[103]\trandom_holdout_set_from_training_data's binary_logloss: 0.100289\n",
      "[104]\trandom_holdout_set_from_training_data's binary_logloss: 0.100165\n",
      "[105]\trandom_holdout_set_from_training_data's binary_logloss: 0.100155\n",
      "[106]\trandom_holdout_set_from_training_data's binary_logloss: 0.100345\n",
      "[107]\trandom_holdout_set_from_training_data's binary_logloss: 0.100442\n",
      "[108]\trandom_holdout_set_from_training_data's binary_logloss: 0.100333\n",
      "[109]\trandom_holdout_set_from_training_data's binary_logloss: 0.100291\n",
      "[110]\trandom_holdout_set_from_training_data's binary_logloss: 0.100341\n",
      "[111]\trandom_holdout_set_from_training_data's binary_logloss: 0.100314\n",
      "[112]\trandom_holdout_set_from_training_data's binary_logloss: 0.100241\n",
      "[113]\trandom_holdout_set_from_training_data's binary_logloss: 0.100335\n",
      "[114]\trandom_holdout_set_from_training_data's binary_logloss: 0.100364\n",
      "[115]\trandom_holdout_set_from_training_data's binary_logloss: 0.100426\n",
      "[116]\trandom_holdout_set_from_training_data's binary_logloss: 0.100513\n",
      "[117]\trandom_holdout_set_from_training_data's binary_logloss: 0.100506\n",
      "[118]\trandom_holdout_set_from_training_data's binary_logloss: 0.100523\n",
      "[119]\trandom_holdout_set_from_training_data's binary_logloss: 0.100444\n",
      "[120]\trandom_holdout_set_from_training_data's binary_logloss: 0.100659\n",
      "[121]\trandom_holdout_set_from_training_data's binary_logloss: 0.100646\n",
      "[122]\trandom_holdout_set_from_training_data's binary_logloss: 0.100542\n",
      "[123]\trandom_holdout_set_from_training_data's binary_logloss: 0.100452\n",
      "[124]\trandom_holdout_set_from_training_data's binary_logloss: 0.100469\n",
      "[125]\trandom_holdout_set_from_training_data's binary_logloss: 0.100509\n",
      "[126]\trandom_holdout_set_from_training_data's binary_logloss: 0.100399\n",
      "[127]\trandom_holdout_set_from_training_data's binary_logloss: 0.100455\n",
      "[128]\trandom_holdout_set_from_training_data's binary_logloss: 0.100404\n",
      "[129]\trandom_holdout_set_from_training_data's binary_logloss: 0.100459\n",
      "[130]\trandom_holdout_set_from_training_data's binary_logloss: 0.100448\n",
      "[131]\trandom_holdout_set_from_training_data's binary_logloss: 0.100443\n",
      "[132]\trandom_holdout_set_from_training_data's binary_logloss: 0.100491\n",
      "[133]\trandom_holdout_set_from_training_data's binary_logloss: 0.100483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134]\trandom_holdout_set_from_training_data's binary_logloss: 0.100361\n",
      "[135]\trandom_holdout_set_from_training_data's binary_logloss: 0.100425\n",
      "[136]\trandom_holdout_set_from_training_data's binary_logloss: 0.100482\n",
      "[137]\trandom_holdout_set_from_training_data's binary_logloss: 0.10051\n",
      "[138]\trandom_holdout_set_from_training_data's binary_logloss: 0.100563\n",
      "[139]\trandom_holdout_set_from_training_data's binary_logloss: 0.100562\n",
      "[140]\trandom_holdout_set_from_training_data's binary_logloss: 0.100575\n",
      "[141]\trandom_holdout_set_from_training_data's binary_logloss: 0.10066\n",
      "[142]\trandom_holdout_set_from_training_data's binary_logloss: 0.100717\n",
      "[143]\trandom_holdout_set_from_training_data's binary_logloss: 0.100659\n",
      "[144]\trandom_holdout_set_from_training_data's binary_logloss: 0.100546\n",
      "[145]\trandom_holdout_set_from_training_data's binary_logloss: 0.100557\n",
      "[146]\trandom_holdout_set_from_training_data's binary_logloss: 0.100855\n",
      "Early stopping, best iteration is:\n",
      "[46]\trandom_holdout_set_from_training_data's binary_logloss: 0.0986023\n",
      "Finished training the pipeline!\n",
      "Total training time:\n",
      "0:00:02\n",
      "\n",
      "\n",
      "Here are the results from our LGBMClassifier\n",
      "predicting Criminal\n",
      "Calculating feature responses, for advanced analytics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The printed list will only contain at most the top 100 features.\n",
      "+---------+----------------+--------------+---------------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "|         | Feature Name   |   Importance |         Delta |   FR_Decrementing |   FR_Incrementing |   FRD_abs |   FRI_abs |   FRD_MAD |   FRI_MAD |\n",
      "|---------+----------------+--------------+---------------+-------------------+-------------------+-----------+-----------+-----------+-----------|\n",
      "| 35.0000 | IIOTHHLT       |            0 |        1.3674 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 21.0000 | HLNVCOST       |            0 |        6.7521 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 22.0000 | HLNVOFFR       |            0 |        6.6605 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 23.0000 | HLNVREF        |            0 |        6.6104 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 24.0000 | HLNVNEED       |            0 |        6.6874 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 25.0000 | HLNVSOR        |            0 |        6.6759 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 27.0000 | IIMCDCHP       |            0 |        0.0884 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 29.0000 | IIMEDICR       |            0 |        0.0752 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 30.0000 | IRCHMPUS       |            0 |        0.0980 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 31.0000 | IICHMPUS       |            0 |        0.0512 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 33.0000 | IIPRVHLT       |            0 |        0.0908 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 34.0000 | IROTHHLT       |            0 |       16.5432 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 36.0000 | HLCALLFG       |            0 |        1.0143 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 37.0000 | HLCALL99       |            0 |        1.0143 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 38.0000 | ANYHLTI2       |            0 |        4.5760 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 39.0000 | IRINSUR4       |            0 |        0.1521 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 40.0000 | IIINSUR4       |            0 |        0.0976 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 19.0000 | HLCLAST        |            0 |       14.3716 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 20.0000 | HLLOSRSN       |            0 |       12.7572 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  8.0000 | IIHH65_2       |            0 |        0.0794 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 16.0000 | HLTINNOS       |            0 |       16.3691 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  4.0000 | IIHHSIZ2       |            0 |        0.0256 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 53.0000 | IIFAMSVC       |            0 |        0.0723 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  6.0000 | IIKI17_2       |            0 |        0.0626 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 52.0000 | IRFAMSVC       |            0 |        0.0965 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 49.0000 | IIFSTAMP       |            0 |        0.0572 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 67.0000 | AIIND102       |            1 |        0.0664 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 66.0000 | MAIIN102       |            1 |        0.0660 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 46.0000 | IRFAMSSI       |            1 |        0.1289 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 11.0000 | MEDICARE       |            1 |        3.5006 |            0.0000 |           -0.0001 |    0.0002 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 47.0000 | IIFAMSSI       |            1 |        0.0884 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 51.0000 | IIFAMPMT       |            2 |        0.0834 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 63.0000 | TROUBUND       |            2 |        2.9259 |            0.0010 |           -0.0001 |    0.0010 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 32.0000 | IRPRVHLT       |            2 |        0.2430 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 62.0000 | TOOLONG        |            2 |        2.9265 |            0.0011 |           -0.0001 |    0.0012 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 13.0000 | CHAMPUS        |            2 |        2.4021 |            0.0000 |           -0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 14.0000 | PRVHLTIN       |            2 |        4.2372 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 26.0000 | IRMCDCHP       |            3 |        0.2084 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 45.0000 | IIFAMSOC       |            3 |        0.0872 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 43.0000 | CELLWRKNG      |            3 |        1.8809 |           -0.0000 |            0.0006 |    0.0001 |    0.0019 |    0.0000 |    0.0000 |\n",
      "| 48.0000 | IRFSTAMP       |            5 |        0.2009 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 54.0000 | IRWELMOS       |            5 |       10.1549 |           -0.0002 |            0.0002 |    0.0003 |    0.0002 |    0.0000 |    0.0000 |\n",
      "| 58.0000 | IIPINC3        |            5 |        0.1631 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 41.0000 | OTHINS         |            5 |        0.1768 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 64.0000 | PDEN10         |            5 |        0.3101 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 12.0000 | CAIDCHIP       |            6 |        4.0730 |           -0.0009 |            0.0001 |    0.0010 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 50.0000 | IRFAMPMT       |            6 |        0.0731 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  7.0000 | IRHH65_2       |            6 |        0.2394 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  2.0000 | NRCH17_2       |            6 |        0.4413 |            0.0000 |            0.0003 |    0.0000 |    0.0010 |    0.0000 |    0.0000 |\n",
      "| 28.0000 | IRMEDICR       |            6 |        0.1395 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 55.0000 | IIWELMOS       |            7 |        0.9200 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 17.0000 | HLCNOTYR       |            7 |       15.2897 |           -0.0023 |            0.0001 |    0.0035 |    0.0003 |    0.0000 |    0.0000 |\n",
      "| 10.0000 | PRXYDATA       |            7 |       22.4089 |            0.0002 |           -0.0002 |    0.0002 |    0.0002 |    0.0000 |    0.0000 |\n",
      "|  9.0000 | PRXRETRY       |            7 |        6.2016 |           -0.0147 |            0.0000 |    0.0148 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 60.0000 | GOVTPROG       |            7 |        0.2144 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 59.0000 | IIFAMIN3       |            8 |        0.2937 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 65.0000 | COUTYP2        |            8 |        0.3875 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 70.0000 | VEREP          |            9 |        0.2499 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  5.0000 | IRKI17_2       |           11 |        0.5499 |           -0.0010 |            0.0007 |    0.0014 |    0.0017 |    0.0000 |    0.0000 |\n",
      "| 42.0000 | CELLNOTCL      |           12 |        2.0052 |            0.0015 |           -0.0012 |    0.0032 |    0.0025 |    0.0000 |    0.0000 |\n",
      "| 44.0000 | IRFAMSOC       |           16 |        0.1870 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "| 18.0000 | HLCNOTMO       |           16 |       12.0904 |           -0.0026 |            0.0007 |    0.0028 |    0.0009 |    0.0000 |    0.0000 |\n",
      "|  1.0000 | IFATHER        |           17 |        0.5964 |            0.0535 |           -0.0001 |    0.0539 |    0.0001 |    0.0000 |    0.0000 |\n",
      "| 61.0000 | POVERTY3       |           19 |        0.4193 |            0.0000 |            0.0000 |    0.0000 |    0.0000 |    0.0000 |    0.0000 |\n",
      "|  3.0000 | IRHHSIZ2       |           22 |        0.7115 |            0.0011 |           -0.0013 |    0.0018 |    0.0019 |    0.0000 |    0.0000 |\n",
      "| 56.0000 | IRPINC3        |           36 |        0.9908 |            0.0101 |           -0.0144 |    0.0109 |    0.0158 |    0.0000 |    0.0000 |\n",
      "| 69.0000 | VESTR          |           45 |        7.3533 |           -0.0007 |            0.0000 |    0.0026 |    0.0029 |    0.0000 |    0.0000 |\n",
      "| 15.0000 | GRPHLTIN       |           61 |       23.8426 |            0.1276 |           -0.0009 |    0.1296 |    0.0073 |    0.0000 |    0.0000 |\n",
      "|  0.0000 | PERID          |           63 | 12639091.1099 |            0.0001 |            0.0006 |    0.0030 |    0.0027 |    0.0000 |    0.0000 |\n",
      "| 57.0000 | IRFAMIN3       |           68 |        1.0481 |            0.0345 |           -0.0148 |    0.0357 |    0.0162 |    0.0000 |    0.0000 |\n",
      "| 68.0000 | ANALWT_C       |           71 |     3000.4799 |           -0.0029 |            0.0026 |    0.0062 |    0.0053 |    0.0000 |    0.0000 |\n",
      "+---------+----------------+--------------+---------------+-------------------+-------------------+-----------+-----------+-----------+-----------+\n",
      "\n",
      "\n",
      "*******\n",
      "Legend:\n",
      "Importance = Feature Importance\n",
      "     Explanation: A weighted measure of how much of the variance the model is able to explain is due to this column\n",
      "FR_delta = Feature Response Delta Amount\n",
      "     Explanation: Amount this column was incremented or decremented by to calculate the feature reponses\n",
      "FR_Decrementing = Feature Response From Decrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to subtracting one FR_delta amount from every value in this column\n",
      "FR_Incrementing = Feature Response From Incrementing Values In This Column By One FR_delta\n",
      "     Explanation: Represents how much the predicted output values respond to adding one FR_delta amount to every value in this column\n",
      "FRD_MAD = Feature Response From Decrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if decrementing this feature provokes strong changes that are both positive and negative\n",
      "FRI_MAD = Feature Response From Incrementing- Median Absolute Delta\n",
      "     Explanation: Takes the absolute value of all changes in predictions, then takes the median of those. Useful for seeing if incrementing this feature provokes strong changes that are both positive and negative\n",
      "FRD_abs = Feature Response From Decrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to subtracting one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "FRI_abs = Feature Response From Incrementing Avg Absolute Change\n",
      "     Explanation: What is the average absolute change in predicted output values to adding one FR_delta amount to every value in this column. Useful for seeing if output is sensitive to a feature, but not in a uniformly positive or negative way\n",
      "*******\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<auto_ml.predictor.Predictor at 0x15133294a90>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_descriptions = {\n",
    "  'Criminal': 'output'\n",
    "}\n",
    "training_params = {'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 14\n",
    "                   , 'lambda_l2': 0.001, 'histogram_pool_size': 16384}\n",
    "training_params2 = {'n_estimators': 2000, 'learning_rate': 0.2, 'num_leaves': 10, 'lambda_l2': 0.001, 'histogram_pool_size': 16384}\n",
    "ml_predictor = Predictor(type_of_estimator='classifier'\n",
    "                         , column_descriptions=column_descriptions)\n",
    "\n",
    "ml_predictor.train(train, model_names=['LGBMClassifier'], training_params=training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_score = ml_predictor.score(df_test, df_test.MEDV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7023190\ttest: 0.6617284\tbest: 0.6617284 (0)\ttotal: 55.6ms\tremaining: 13.8s\n",
      "1:\tlearn: 0.7045010\ttest: 0.6658228\tbest: 0.6658228 (1)\ttotal: 123ms\tremaining: 15.3s\n",
      "2:\tlearn: 0.7045010\ttest: 0.6658228\tbest: 0.6658228 (2)\ttotal: 219ms\tremaining: 18s\n",
      "3:\tlearn: 0.7114527\ttest: 0.6743590\tbest: 0.6743590 (3)\ttotal: 301ms\tremaining: 18.5s\n",
      "4:\tlearn: 0.7095079\ttest: 0.6691729\tbest: 0.6743590 (3)\ttotal: 358ms\tremaining: 17.5s\n",
      "5:\tlearn: 0.7168737\ttest: 0.6729223\tbest: 0.6743590 (3)\ttotal: 379ms\tremaining: 15.4s\n",
      "6:\tlearn: 0.7177459\ttest: 0.6770833\tbest: 0.6770833 (6)\ttotal: 477ms\tremaining: 16.5s\n",
      "7:\tlearn: 0.7135851\ttest: 0.6649616\tbest: 0.6770833 (6)\ttotal: 585ms\tremaining: 17.7s\n",
      "8:\tlearn: 0.7105010\ttest: 0.6666667\tbest: 0.6770833 (6)\ttotal: 732ms\tremaining: 19.6s\n",
      "9:\tlearn: 0.7100820\ttest: 0.6675063\tbest: 0.6770833 (6)\ttotal: 1.03s\tremaining: 24.8s\n",
      "10:\tlearn: 0.7111324\ttest: 0.6675063\tbest: 0.6770833 (6)\ttotal: 1.13s\tremaining: 24.5s\n",
      "11:\tlearn: 0.7103118\ttest: 0.6691729\tbest: 0.6770833 (6)\ttotal: 1.18s\tremaining: 23.5s\n",
      "12:\tlearn: 0.7099090\ttest: 0.6691729\tbest: 0.6770833 (6)\ttotal: 1.26s\tremaining: 23.1s\n",
      "13:\tlearn: 0.7108779\ttest: 0.6691729\tbest: 0.6770833 (6)\ttotal: 1.35s\tremaining: 22.7s\n",
      "14:\tlearn: 0.7126546\ttest: 0.6658291\tbest: 0.6770833 (6)\ttotal: 1.41s\tremaining: 22.1s\n",
      "15:\tlearn: 0.7116390\ttest: 0.6666667\tbest: 0.6770833 (6)\ttotal: 1.48s\tremaining: 21.6s\n",
      "16:\tlearn: 0.7116301\ttest: 0.6666667\tbest: 0.6770833 (6)\ttotal: 1.55s\tremaining: 21.3s\n",
      "17:\tlearn: 0.7112172\ttest: 0.6691729\tbest: 0.6770833 (6)\ttotal: 1.62s\tremaining: 20.8s\n",
      "18:\tlearn: 0.7104762\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 1.76s\tremaining: 21.4s\n",
      "19:\tlearn: 0.7113744\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 1.86s\tremaining: 21.4s\n",
      "20:\tlearn: 0.7105513\ttest: 0.6683292\tbest: 0.6770833 (6)\ttotal: 1.93s\tremaining: 21.1s\n",
      "21:\tlearn: 0.7103514\ttest: 0.6683292\tbest: 0.6770833 (6)\ttotal: 2s\tremaining: 20.7s\n",
      "22:\tlearn: 0.7101380\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 2.07s\tremaining: 20.4s\n",
      "23:\tlearn: 0.7108262\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 2.15s\tremaining: 20.2s\n",
      "24:\tlearn: 0.7110266\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 2.21s\tremaining: 19.9s\n",
      "25:\tlearn: 0.7113744\ttest: 0.6675000\tbest: 0.6770833 (6)\ttotal: 2.31s\tremaining: 20s\n",
      "26:\tlearn: 0.7117842\ttest: 0.6691542\tbest: 0.6770833 (6)\ttotal: 2.38s\tremaining: 19.7s\n",
      "27:\tlearn: 0.7120567\ttest: 0.6666667\tbest: 0.6770833 (6)\ttotal: 2.48s\tremaining: 19.7s\n",
      "28:\tlearn: 0.7132701\ttest: 0.6666667\tbest: 0.6770833 (6)\ttotal: 2.63s\tremaining: 20s\n",
      "29:\tlearn: 0.7142180\ttest: 0.6650000\tbest: 0.6770833 (6)\ttotal: 2.71s\tremaining: 19.9s\n",
      "30:\tlearn: 0.7148271\ttest: 0.6650000\tbest: 0.6770833 (6)\ttotal: 3.02s\tremaining: 21.3s\n",
      "31:\tlearn: 0.7143534\ttest: 0.6650000\tbest: 0.6770833 (6)\ttotal: 3.32s\tremaining: 22.6s\n",
      "32:\tlearn: 0.7158444\ttest: 0.6658291\tbest: 0.6770833 (6)\ttotal: 3.42s\tremaining: 22.5s\n",
      "33:\tlearn: 0.7159791\ttest: 0.6649874\tbest: 0.6770833 (6)\ttotal: 3.5s\tremaining: 22.3s\n",
      "34:\tlearn: 0.7158444\ttest: 0.6658291\tbest: 0.6770833 (6)\ttotal: 3.58s\tremaining: 22s\n",
      "35:\tlearn: 0.7161841\ttest: 0.6658291\tbest: 0.6770833 (6)\ttotal: 3.67s\tremaining: 21.8s\n",
      "36:\tlearn: 0.7163188\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 3.76s\tremaining: 21.6s\n",
      "37:\tlearn: 0.7167219\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 3.84s\tremaining: 21.4s\n",
      "38:\tlearn: 0.7176694\ttest: 0.6649874\tbest: 0.6770833 (6)\ttotal: 3.99s\tremaining: 21.6s\n",
      "39:\tlearn: 0.7176694\ttest: 0.6649874\tbest: 0.6770833 (6)\ttotal: 4.13s\tremaining: 21.7s\n",
      "40:\tlearn: 0.7184834\ttest: 0.6624685\tbest: 0.6770833 (6)\ttotal: 4.3s\tremaining: 21.9s\n",
      "41:\tlearn: 0.7186168\ttest: 0.6641414\tbest: 0.6770833 (6)\ttotal: 4.38s\tremaining: 21.7s\n",
      "42:\tlearn: 0.7194313\ttest: 0.6624685\tbest: 0.6770833 (6)\ttotal: 4.52s\tremaining: 21.8s\n",
      "43:\tlearn: 0.7195642\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 4.66s\tremaining: 21.8s\n",
      "44:\tlearn: 0.7195642\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 4.69s\tremaining: 21.4s\n",
      "45:\tlearn: 0.7194313\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 4.77s\tremaining: 21.1s\n",
      "46:\tlearn: 0.7197724\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 4.83s\tremaining: 20.9s\n",
      "47:\tlearn: 0.7194313\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 5.12s\tremaining: 21.6s\n",
      "48:\tlearn: 0.7195642\ttest: 0.6608479\tbest: 0.6770833 (6)\ttotal: 5.19s\tremaining: 21.3s\n",
      "49:\tlearn: 0.7192235\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.29s\tremaining: 21.2s\n",
      "50:\tlearn: 0.7192235\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.32s\tremaining: 20.8s\n",
      "51:\tlearn: 0.7195642\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.41s\tremaining: 20.6s\n",
      "52:\tlearn: 0.7199622\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.51s\tremaining: 20.5s\n",
      "53:\tlearn: 0.7193564\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.55s\tremaining: 20.1s\n",
      "54:\tlearn: 0.7196970\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.61s\tremaining: 19.9s\n",
      "55:\tlearn: 0.7196217\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.75s\tremaining: 19.9s\n",
      "56:\tlearn: 0.7196217\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 5.83s\tremaining: 19.8s\n",
      "57:\tlearn: 0.7196217\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 6.46s\tremaining: 21.4s\n",
      "58:\tlearn: 0.7198866\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 6.59s\tremaining: 21.3s\n",
      "59:\tlearn: 0.7198866\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 6.66s\tremaining: 21.1s\n",
      "60:\tlearn: 0.7200189\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 6.8s\tremaining: 21.1s\n",
      "61:\tlearn: 0.7203590\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 6.95s\tremaining: 21.1s\n",
      "62:\tlearn: 0.7205674\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 7.05s\tremaining: 20.9s\n",
      "63:\tlearn: 0.7209632\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 7.19s\tremaining: 20.9s\n",
      "64:\tlearn: 0.7214353\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 7.8s\tremaining: 22.2s\n",
      "65:\tlearn: 0.7212264\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 7.87s\tremaining: 21.9s\n",
      "66:\tlearn: 0.7202073\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 7.93s\tremaining: 21.7s\n",
      "67:\tlearn: 0.7208098\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 9.93s\tremaining: 26.6s\n",
      "68:\tlearn: 0.7211493\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10s\tremaining: 26.2s\n",
      "69:\tlearn: 0.7211493\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.1s\tremaining: 25.9s\n",
      "70:\tlearn: 0.7211493\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.1s\tremaining: 25.5s\n",
      "71:\tlearn: 0.7210179\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.2s\tremaining: 25.2s\n",
      "72:\tlearn: 0.7210179\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.3s\tremaining: 24.9s\n",
      "73:\tlearn: 0.7213579\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.4s\tremaining: 24.6s\n",
      "74:\tlearn: 0.7213579\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.4s\tremaining: 24.3s\n",
      "75:\tlearn: 0.7216203\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 10.7s\tremaining: 24.5s\n",
      "76:\tlearn: 0.7216203\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 10.8s\tremaining: 24.2s\n",
      "77:\tlearn: 0.7219604\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 10.9s\tremaining: 24s\n",
      "78:\tlearn: 0.7224317\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 12.9s\tremaining: 27.8s\n",
      "79:\tlearn: 0.7225624\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 13s\tremaining: 27.5s\n",
      "80:\tlearn: 0.7226930\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 13.1s\tremaining: 27.3s\n",
      "81:\tlearn: 0.7226930\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 13.1s\tremaining: 26.9s\n",
      "82:\tlearn: 0.7223529\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 13.2s\tremaining: 26.6s\n",
      "83:\tlearn: 0.7223529\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 13.2s\tremaining: 26.2s\n",
      "84:\tlearn: 0.7226930\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.2s\tremaining: 31.4s\n",
      "85:\tlearn: 0.7228235\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.3s\tremaining: 31s\n",
      "86:\tlearn: 0.7228235\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.3s\tremaining: 30.6s\n",
      "87:\tlearn: 0.7231638\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.6s\tremaining: 30.6s\n",
      "88:\tlearn: 0.7231638\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.7s\tremaining: 30.2s\n",
      "89:\tlearn: 0.7235045\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 16.8s\tremaining: 29.8s\n",
      "90:\tlearn: 0.7233742\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 16.9s\tremaining: 29.5s\n",
      "91:\tlearn: 0.7232438\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 17s\tremaining: 29.3s\n",
      "92:\tlearn: 0.7240566\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 17.2s\tremaining: 29s\n",
      "93:\tlearn: 0.7238454\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 17.3s\tremaining: 28.6s\n",
      "94:\tlearn: 0.7246582\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 17.9s\tremaining: 29.2s\n",
      "95:\tlearn: 0.7247879\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 17.9s\tremaining: 28.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96:\tlearn: 0.7255179\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 19.1s\tremaining: 30.1s\n",
      "97:\tlearn: 0.7267168\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 21.1s\tremaining: 32.8s\n",
      "98:\tlearn: 0.7261625\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 21.3s\tremaining: 32.5s\n",
      "99:\tlearn: 0.7280000\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 22.4s\tremaining: 33.7s\n",
      "100:\tlearn: 0.7289412\ttest: 0.6633166\tbest: 0.6770833 (6)\ttotal: 25.6s\tremaining: 37.8s\n",
      "101:\tlearn: 0.7290292\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 25.7s\tremaining: 37.3s\n",
      "102:\tlearn: 0.7292844\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 29s\tremaining: 41.4s\n",
      "103:\tlearn: 0.7298824\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 32s\tremaining: 44.9s\n",
      "104:\tlearn: 0.7298824\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 32.3s\tremaining: 44.6s\n",
      "105:\tlearn: 0.7300094\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 32.9s\tremaining: 44.7s\n",
      "106:\tlearn: 0.7306065\ttest: 0.6616541\tbest: 0.6770833 (6)\ttotal: 33.2s\tremaining: 44.4s\n",
      "107:\tlearn: 0.7318909\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 36.4s\tremaining: 47.9s\n",
      "108:\tlearn: 0.7319830\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 36.5s\tremaining: 47.2s\n",
      "109:\tlearn: 0.7319830\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 36.5s\tremaining: 46.5s\n",
      "110:\tlearn: 0.7320169\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 39.8s\tremaining: 49.8s\n",
      "111:\tlearn: 0.7321429\ttest: 0.6600000\tbest: 0.6770833 (6)\ttotal: 39.8s\tremaining: 49.1s\n",
      "112:\tlearn: 0.7326128\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 40.5s\tremaining: 49.1s\n",
      "113:\tlearn: 0.7326128\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 40.6s\tremaining: 48.4s\n",
      "114:\tlearn: 0.7328638\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 43.6s\tremaining: 51.2s\n",
      "115:\tlearn: 0.7328638\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 43.7s\tremaining: 50.4s\n",
      "116:\tlearn: 0.7341475\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 46.7s\tremaining: 53.1s\n",
      "117:\tlearn: 0.7342723\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 46.7s\tremaining: 52.3s\n",
      "118:\tlearn: 0.7340525\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 46.8s\tremaining: 51.6s\n",
      "119:\tlearn: 0.7341772\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 46.9s\tremaining: 50.8s\n",
      "120:\tlearn: 0.7347418\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 47s\tremaining: 50.1s\n",
      "121:\tlearn: 0.7353355\ttest: 0.6641604\tbest: 0.6770833 (6)\ttotal: 47s\tremaining: 49.4s\n",
      "122:\tlearn: 0.7359287\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 47.6s\tremaining: 49.2s\n",
      "123:\tlearn: 0.7360525\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 48.2s\tremaining: 49s\n",
      "124:\tlearn: 0.7362998\ttest: 0.6625000\tbest: 0.6770833 (6)\ttotal: 48.3s\tremaining: 48.3s\n",
      "125:\tlearn: 0.7362998\ttest: 0.6633416\tbest: 0.6770833 (6)\ttotal: 48.4s\tremaining: 47.7s\n",
      "126:\tlearn: 0.7374825\ttest: 0.6616915\tbest: 0.6770833 (6)\ttotal: 51.5s\tremaining: 49.9s\n",
      "127:\tlearn: 0.7379504\ttest: 0.6633416\tbest: 0.6770833 (6)\ttotal: 51.7s\tremaining: 49.2s\n",
      "128:\tlearn: 0.7381954\ttest: 0.6633416\tbest: 0.6770833 (6)\ttotal: 52.3s\tremaining: 49s\n",
      "129:\tlearn: 0.7381954\ttest: 0.6616915\tbest: 0.6770833 (6)\ttotal: 52.3s\tremaining: 48.3s\n",
      "130:\tlearn: 0.7381954\ttest: 0.6616915\tbest: 0.6770833 (6)\ttotal: 52.4s\tremaining: 47.6s\n",
      "131:\tlearn: 0.7381954\ttest: 0.6616915\tbest: 0.6770833 (6)\ttotal: 52.4s\tremaining: 46.9s\n",
      "132:\tlearn: 0.7381954\ttest: 0.6633416\tbest: 0.6770833 (6)\ttotal: 52.5s\tremaining: 46.2s\n",
      "133:\tlearn: 0.7381954\ttest: 0.6633416\tbest: 0.6770833 (6)\ttotal: 54.5s\tremaining: 47.1s\n",
      "134:\tlearn: 0.7391304\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 57.4s\tremaining: 48.9s\n",
      "135:\tlearn: 0.7390289\ttest: 0.6584158\tbest: 0.6770833 (6)\ttotal: 57.4s\tremaining: 48.1s\n",
      "136:\tlearn: 0.7394958\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 57.5s\tremaining: 47.5s\n",
      "137:\tlearn: 0.7393741\ttest: 0.6608911\tbest: 0.6770833 (6)\ttotal: 57.6s\tremaining: 46.7s\n",
      "138:\tlearn: 0.7396367\ttest: 0.6592593\tbest: 0.6770833 (6)\ttotal: 57.7s\tremaining: 46.1s\n",
      "139:\tlearn: 0.7393939\ttest: 0.6592593\tbest: 0.6770833 (6)\ttotal: 57.8s\tremaining: 45.4s\n",
      "140:\tlearn: 0.7395154\ttest: 0.6592593\tbest: 0.6770833 (6)\ttotal: 57.9s\tremaining: 44.8s\n",
      "141:\tlearn: 0.7397579\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 1s\tremaining: 46.4s\n",
      "142:\tlearn: 0.7397579\ttest: 0.6625310\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 48s\n",
      "143:\tlearn: 0.7401209\ttest: 0.6625310\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 47.3s\n",
      "144:\tlearn: 0.7402416\ttest: 0.6608911\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 46.6s\n",
      "145:\tlearn: 0.7402416\ttest: 0.6608911\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 45.8s\n",
      "146:\tlearn: 0.7402416\ttest: 0.6608911\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 45.1s\n",
      "147:\tlearn: 0.7401209\ttest: 0.6592593\tbest: 0.6770833 (6)\ttotal: 1m 4s\tremaining: 44.4s\n",
      "148:\tlearn: 0.7431618\ttest: 0.6584158\tbest: 0.6770833 (6)\ttotal: 1m 7s\tremaining: 45.8s\n",
      "149:\tlearn: 0.7456059\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 47.1s\n",
      "150:\tlearn: 0.7456059\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 46.3s\n",
      "151:\tlearn: 0.7452612\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 45.6s\n",
      "152:\tlearn: 0.7452612\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 44.9s\n",
      "153:\tlearn: 0.7453789\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 44.2s\n",
      "154:\tlearn: 0.7456059\ttest: 0.6600496\tbest: 0.6770833 (6)\ttotal: 1m 10s\tremaining: 43.5s\n",
      "155:\tlearn: 0.7457235\ttest: 0.6584158\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 42.8s\n",
      "156:\tlearn: 0.7457235\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 42.2s\n",
      "157:\tlearn: 0.7457235\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 41.5s\n",
      "158:\tlearn: 0.7457235\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 40.9s\n",
      "159:\tlearn: 0.7459584\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 40.2s\n",
      "160:\tlearn: 0.7459584\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 39.5s\n",
      "161:\tlearn: 0.7461859\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 38.9s\n",
      "162:\tlearn: 0.7469935\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 38.4s\n",
      "163:\tlearn: 0.7466482\ttest: 0.6576355\tbest: 0.6770833 (6)\ttotal: 1m 11s\tremaining: 37.7s\n",
      "164:\tlearn: 0.7476895\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 12s\tremaining: 37.1s\n",
      "165:\tlearn: 0.7480388\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 15s\tremaining: 38.1s\n",
      "166:\tlearn: 0.7480388\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 15s\tremaining: 37.4s\n",
      "167:\tlearn: 0.7475773\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 15s\tremaining: 36.8s\n",
      "168:\tlearn: 0.7475773\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 15s\tremaining: 36.2s\n",
      "169:\tlearn: 0.7480388\ttest: 0.6600985\tbest: 0.6770833 (6)\ttotal: 1m 18s\tremaining: 37s\n",
      "170:\tlearn: 0.7480388\ttest: 0.6600985\tbest: 0.6770833 (6)\ttotal: 1m 18s\tremaining: 36.4s\n",
      "171:\tlearn: 0.7483841\ttest: 0.6609337\tbest: 0.6770833 (6)\ttotal: 1m 19s\tremaining: 35.9s\n",
      "172:\tlearn: 0.7483841\ttest: 0.6609337\tbest: 0.6770833 (6)\ttotal: 1m 19s\tremaining: 35.2s\n",
      "173:\tlearn: 0.7483841\ttest: 0.6609337\tbest: 0.6770833 (6)\ttotal: 1m 19s\tremaining: 34.6s\n",
      "174:\tlearn: 0.7491932\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 19s\tremaining: 34s\n",
      "175:\tlearn: 0.7491932\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 19s\tremaining: 33.4s\n",
      "176:\tlearn: 0.7501153\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 20s\tremaining: 33.2s\n",
      "177:\tlearn: 0.7501153\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 20s\tremaining: 32.6s\n",
      "178:\tlearn: 0.7501153\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 20s\tremaining: 32s\n",
      "179:\tlearn: 0.7497696\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 20s\tremaining: 31.4s\n",
      "180:\tlearn: 0.7506912\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 20s\tremaining: 30.9s\n",
      "181:\tlearn: 0.7508061\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 21s\tremaining: 30.3s\n",
      "182:\tlearn: 0.7508061\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 21s\tremaining: 29.7s\n",
      "183:\tlearn: 0.7508061\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 21s\tremaining: 29.1s\n",
      "184:\tlearn: 0.7509208\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 21s\tremaining: 28.6s\n",
      "185:\tlearn: 0.7520737\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 21s\tremaining: 28.2s\n",
      "186:\tlearn: 0.7520737\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 22s\tremaining: 27.6s\n",
      "187:\tlearn: 0.7521879\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 22s\tremaining: 27.2s\n",
      "188:\tlearn: 0.7518416\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 22s\tremaining: 26.7s\n",
      "189:\tlearn: 0.7523020\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 22s\tremaining: 26.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190:\tlearn: 0.7535698\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 23s\tremaining: 25.7s\n",
      "191:\tlearn: 0.7535698\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 23s\tremaining: 25.1s\n",
      "192:\tlearn: 0.7535632\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 23s\tremaining: 24.6s\n",
      "193:\tlearn: 0.7551772\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 24.9s\n",
      "194:\tlearn: 0.7549425\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 24.4s\n",
      "195:\tlearn: 0.7549425\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 23.8s\n",
      "196:\tlearn: 0.7554023\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 23.3s\n",
      "197:\tlearn: 0.7552898\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 22.8s\n",
      "198:\tlearn: 0.7550551\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 22.2s\n",
      "199:\tlearn: 0.7563218\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 21.7s\n",
      "200:\tlearn: 0.7565578\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 26s\tremaining: 21.2s\n",
      "201:\tlearn: 0.7565578\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 27s\tremaining: 20.7s\n",
      "202:\tlearn: 0.7564457\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 30s\tremaining: 20.9s\n",
      "203:\tlearn: 0.7571297\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 30s\tremaining: 20.4s\n",
      "204:\tlearn: 0.7573529\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 30s\tremaining: 19.9s\n",
      "205:\tlearn: 0.7572281\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 32s\tremaining: 19.8s\n",
      "206:\tlearn: 0.7575758\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 32s\tremaining: 19.3s\n",
      "207:\tlearn: 0.7572281\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 32s\tremaining: 18.7s\n",
      "208:\tlearn: 0.7574644\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 32s\tremaining: 18.2s\n",
      "209:\tlearn: 0.7579237\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 33s\tremaining: 17.7s\n",
      "210:\tlearn: 0.7578125\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 33s\tremaining: 17.2s\n",
      "211:\tlearn: 0.7578125\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 33s\tremaining: 16.7s\n",
      "212:\tlearn: 0.7584785\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 36s\tremaining: 16.7s\n",
      "213:\tlearn: 0.7588262\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 38s\tremaining: 16.5s\n",
      "214:\tlearn: 0.7591743\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 38s\tremaining: 16s\n",
      "215:\tlearn: 0.7592847\ttest: 0.6584767\tbest: 0.6770833 (6)\ttotal: 1m 38s\tremaining: 15.5s\n",
      "216:\tlearn: 0.7589368\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 38s\tremaining: 15.1s\n",
      "217:\tlearn: 0.7588262\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 39s\tremaining: 14.5s\n",
      "218:\tlearn: 0.7589368\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 39s\tremaining: 14s\n",
      "219:\tlearn: 0.7589368\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 39s\tremaining: 13.5s\n",
      "220:\tlearn: 0.7589204\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 39s\tremaining: 13.1s\n",
      "221:\tlearn: 0.7592677\ttest: 0.6601467\tbest: 0.6770833 (6)\ttotal: 1m 39s\tremaining: 12.6s\n",
      "222:\tlearn: 0.7608795\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 42s\tremaining: 12.4s\n",
      "223:\tlearn: 0.7612282\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 43s\tremaining: 12s\n",
      "224:\tlearn: 0.7612282\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 43s\tremaining: 11.5s\n",
      "225:\tlearn: 0.7612282\ttest: 0.6593137\tbest: 0.6770833 (6)\ttotal: 1m 43s\tremaining: 11s\n",
      "226:\tlearn: 0.7622763\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 45s\tremaining: 10.7s\n",
      "227:\tlearn: 0.7621448\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 45s\tremaining: 10.2s\n",
      "228:\tlearn: 0.7624943\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 45s\tremaining: 9.66s\n",
      "229:\tlearn: 0.7621448\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 45s\tremaining: 9.16s\n",
      "230:\tlearn: 0.7627119\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 48s\tremaining: 8.91s\n",
      "231:\tlearn: 0.7628205\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 48s\tremaining: 8.41s\n",
      "232:\tlearn: 0.7643021\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 51s\tremaining: 8.13s\n",
      "233:\tlearn: 0.7643021\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 51s\tremaining: 7.62s\n",
      "234:\tlearn: 0.7639269\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 53s\tremaining: 7.24s\n",
      "235:\tlearn: 0.7642759\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 53s\tremaining: 6.73s\n",
      "236:\tlearn: 0.7641682\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 53s\tremaining: 6.23s\n",
      "237:\tlearn: 0.7641682\ttest: 0.6560976\tbest: 0.6770833 (6)\ttotal: 1m 53s\tremaining: 5.73s\n",
      "238:\tlearn: 0.7641682\ttest: 0.6577017\tbest: 0.6770833 (6)\ttotal: 1m 53s\tremaining: 5.24s\n",
      "239:\tlearn: 0.7640347\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 54s\tremaining: 4.79s\n",
      "240:\tlearn: 0.7645985\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 55s\tremaining: 4.32s\n",
      "241:\tlearn: 0.7647059\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 55s\tremaining: 3.83s\n",
      "242:\tlearn: 0.7647059\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 3.37s\n",
      "243:\tlearn: 0.7648131\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 2.88s\n",
      "244:\tlearn: 0.7651619\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 2.39s\n",
      "245:\tlearn: 0.7649475\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 1.91s\n",
      "246:\tlearn: 0.7650547\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 1.43s\n",
      "247:\tlearn: 0.7651619\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 947ms\n",
      "248:\tlearn: 0.7651619\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 472ms\n",
      "249:\tlearn: 0.7650547\ttest: 0.6585366\tbest: 0.6770833 (6)\ttotal: 1m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6770833333\n",
      "bestIteration = 6\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15171c7acf8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple = CatBoostClassifier(\n",
    "    eval_metric='Precision',\n",
    "    depth=10,\n",
    "    iterations=250,\n",
    "    random_seed=42,\n",
    "    use_best_model=False\n",
    ")\n",
    "model_simple.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=[],\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_simple.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = ml_predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = pd.DataFrame({'PERID':test.PERID, 'Criminal':[int(i) for i in predicted]})\n",
    "sub2 = sub2[['PERID', 'Criminal']]\n",
    "sub2.to_csv('sub_edit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
